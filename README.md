# Desafio Processo Seletivo Bazico â‰ 

## O desafio consiste em responder 06 perguntas que cobrem uma ampla gama de competÃªncias, desde conhecimentos prÃ¡ticos de programaÃ§Ã£o e anÃ¡lise atÃ© a capacidade de abordar problemas de negÃ³cios com um pensamento analÃ­tico.

Autor: SÃ©rgio ManhÃ£es Moura Filho
> Os cÃ³digos abaixo foram feitos fora de contexto, apenas para exemplificar, a nomeaÃ§Ã£o das variÃ¡veis e tabelas foi feita por convenÃ§Ã£o minha. 

## ğŸ¢ **QuestÃ£o 1 (SQL)**

Considerando a tabela clientes do schema bazico e considerando que hÃ¡ um elemento Primary Key "identificador", que Ã© um inteiro AUTO_INCREMENT e cpf sendo um campo que nÃ£o pode haver duplicatas, a identificaÃ§Ã£o de duplicatas pode ser feito:

```SQL
SELECT cpf, COUNT(*) FROM bazico.clientes
GROUP BY cpf
WHERE COUNT(*) > 1;

```

Para a exclusÃ£o, Ã© necessÃ¡rio que pelo menos a primeira ocorrencia seja mantida, pode ser feito um subselect para encontrar o menor identificador e excluir os outros. Particularmente, nÃ£o trabalhei com esse tipo de ocorrencia, mas pode ser algo do tipo:

```SQL
DELETE FROM bazico.clientes
WHERE identificador NOT IN (SELECT MIN(identificador) FROM bazico.clientes GROUP BY cpf);
```

Com isso, Ã© possÃ­vel excluir todas as duplicatas, mantendo a primeira ocorrencia.


## ğŸ **QuestÃ£o 2 (Python)**

Considerando um arquivo de interesse "sales.csv" e o import das bibliotecas Numpy e Pandas.

Explicando: Utilizaria a biblioteca Pandas para primeiramente, importar o csv a partir da funÃ§Ã£o 

```python
 bd = pandas.read_csv("sales.csv") 
```

A partir dessa disposiÃ§Ã£o, para facilitar o tratamento e limpeza, converteria para um Dataframe, tipo de dados do prÃ³prio Pandas. Considerando que o csv lido foi armazenado na variÃ¡vel bd.

```python
 df_vendas = pandas.Dataframe(bd)
```

Com isso, temos o necessÃ¡rio para realizar uma limpeza e tratar valores ausentes. Primeiramente, limpando os dados, Ã© necessÃ¡rio que todas as colunas sigam um padrÃ£o de tipo, entÃ£o procuraria, nas colunas de valor, considerando valores numÃ©ricos com casa decimal, reforÃ§ar com um:

 ```python
  df_vendas = df_vendas.apply(lambda x: float(x['valor']))
```
E analogamente para qualquer outro campo que necessite de uma validaÃ§Ã£o de tipo. Caso alguma linha nÃ£o possa ser convertida, vale a anÃ¡lise individual, caso nÃ£o se encaixe a linha pode ser removida.

Para tratar dados faltantes, existem algumas maneiras. No caso de valores de texto, que nÃ£o serÃ£o utilizados pra cÃ¡lculos e que nÃ£o tenham uma certa relevÃ¢ncia na anÃ¡lise dos dados, pode ser substituita por um valor padrÃ£o, por exemplo:
Uma coluna chamada nome pode ser substituida por 'desconhecido' ou 'nÃ£o informado'. Isso pode ser feito facilmente usando:

```python

df_vendas[['nome']] =df_vendas[['nome']].fillna(value="desconhecido")

```

JÃ¡ se tratando de nÃºmeros, Ã© um pouco mais complicado, pois pode afetar diretamente a anÃ¡lise do que estÃ¡ sendo pedido, contudo, se tratando de uma base que tem informaÃ§Ãµes de um produto, Ã© possivel fazer uma associaÃ§Ã£o direta do nome do produto com seu preÃ§o determinado, por exemplo:

```python

# supondo que o elemento do df_vendas tem os campos nome,preco,data

produto = {"camisa_bazica_preta":140.00}

for produto in df_vendas:
    if produto['preco'] == None:
        produto['preco'] = produto[produto['nome']]

```
Nesse caso, se o preÃ§o do produto nÃ£o estiver informado, ele serÃ¡ substituido pelo preÃ§o associado ao nome do produto.

Outro caso Ã© substituir por um valor padrÃ£o, que geralmente Ã© a media dos valores da coluna, o que nÃ£o Ã© o ideal para uma anÃ¡lise meticulosa.

Com tudo certo, Ã© possÃ­vel realizar anÃ¡lises baseadas no tipo do produto, preÃ§o, nome do cliente, etc. 

MÃ©tricas interessante que podem ser feitas Ã© identificar por exemplo: os produtos mais vendidos e a comparaÃ§Ã£o com o montante de todos os produtos, tendo assim uma participaÃ§Ã£o relativa com o total. Outra Ã© considerar as cores de camisa mais compradas, o que pode facilitar na reposiÃ§Ã£o do estoque.

AlÃ©m disso, com a data de compras tambÃ©m Ã© possÃ­vel ter uma estimativa dos dias mais lucrativos ou mais movimentados do mÃªs na empresa, que pode ajudar na organizaÃ§Ã£o da logistica de entregas.

AlÃ©m disso, com o armazenamento a longo prazo, Ã© possÃ­vel criar um robusto grÃ¡fico com a comparaÃ§Ã£o mÃªs a mÃªs do valor das vendas e criar uma automaÃ§Ã£o para criar um csv para salvar um resumo por mÃªs, bimestre ou atÃ© anual.


## ğŸ“Š **QuestÃ£o 3 (Ferramentas de AnÃ¡lise)**

JÃ¡ utilizei: Matplotlib (90%) Seaborn (10%)


>A anÃ¡lise abaixo foi feita no Ãºltimo mÃªs em um projeto junto Ã  LADATA e Mangue Jornalisto para analisar o eleitorado de Aracaju. Os grÃ¡ficos foram gerados separadamente e juntos apenas para propÃ³sito de visualizaÃ§Ã£o nesse processo Seletivo

![AnÃ¡lise Eleitorado Aracaju](./assets/resumo_analise_mangue.png)

>Esse segundo grÃ¡fico, ainda que mais simples, foi utilizado para analisar a eficiÃªncia de dois algoritmos, que foram utilizados para a classificaÃ§Ã£o de modelos no meu projeto de Pesquisa.

![BoxPlot](./assets/image-1.png)

>Esse Ãºltimo grÃ¡fico estÃ¡ sendo utilizado em meu TCC para analisar a tendencia de potÃªncia elÃ©trica de aparelhos de uma residÃªncia, para posteriormente gerar um modelo de previsÃ£o de consumo de energia e classificaÃ§Ã£o de aparelhos.

![alt text](./assets/img_TCC.png)

## ğŸ§‘â€ğŸ’¼ **QuestÃ£o 4 (Problema de NegÃ³cio com Dados)**


Para esse tipo de problema, Ã© importante saber desde quando a base de dados estÃ¡ sendo construida, Ã© interessante analisar a tendencia com o passar de anos, por exemplo, para ter uma tendÃªncia em cada mÃªs ou perÃ­odo. 
Apesar disso, Ã© possÃ­vel fazer uma anÃ¡lise mÃªs a mÃªs considerando as datas e dias de semana mais movimentados da loja. Seja quando um anuncio novo Ã© soltado nas redes sociais ou um grande evento, como a Black Friday ou um saldÃ£o. Considerando isso, Ã© possivel realizar uma regressÃ£o Linear considerando a data e as vendas associadas Ã quela data todos os meses, ou a estimativa de numeros de venda de um produto ou da loja inteira no mÃªs.

O resultado do algoritmo Ã© uma estimativa de valores futuros considerando qualquer possivel desvio ou erro associado, que tendem a diminuir com a robustez do modelo.


Uma maneira mais simples, pode ser considerar a mÃ©dia das vendas por mÃªs jÃ¡ cadastradas e considerar a mÃ©dia por mÃªs, considerando o desvio padrÃ£o como um possÃ­vel erro previsto. 


## âŒ¨ï¸ **QuestÃ£o 5 (TransformaÃ§Ã£o de Dados)**

Os projetos que necessitei uma ETL foram mais voltados para a GraduaÃ§Ã£o, principalmente nos de Machine Learning, onde era necessÃ¡rio juntar informaÃ§Ãµes de 8 bases de dados sobre elementos arquitetÃ´nicos e realizar treinamento utilizando Ã¡rvores de decisÃ£o. No processo, eu precisava juntar as informaÃ§Ãµes de cada base de dados, adicionar os labels e fazer a divisÃ£o de treino e teste. No processo foi necessÃ¡rio ajustar alguns campos presentes em uns e nÃ£o em outros e arranjar uma maneira de preencher esse dados faltantes.

Outro exemplo, dessa vez em um projeto pessoal, foi o uso de WebScrapping para coletar dados da Stardew Valley Wiki, onde foi necessÃ¡rio juntar diversas informaÃ§Ãµes de diferentes pÃ¡ginas e transformar em um Ãºnico arquivo csv para ser utilizado em um projeto de anÃ¡lise de dados, que ainda nÃ£o foi finalizado, mas jÃ¡ hÃ¡ versÃµes no Kaggle.

https://www.kaggle.com/datasets/srgiomanhes/stardew-valley-villagers-dataset


## ğŸ‘• **QuestÃ£o 6 (Campanha em Salvador)**

Acompanhando a sÃ©rie do "Da fina ou da grossa", e os stories postados em 23/09/2024, onde foi dito que +500 camisas foram vendidas na capital Bahiana, considerando isso em um periodo de tempo de uma semana, eu arriscaria dizer que por volta de 800 camisas jÃ¡ foram vendidas nesse perÃ­odo de tempo em Salvador, levando em conta de 2 a 3 semanas de campanha e com um possÃ­vel crescimento acelerado na Ãºltima semana. por conta dos anÃºncios e da campanha de marketing.

Sendo um pouco mais especÃ­fico, arricaria a proporÃ§Ã£o, por semana de: 100,200 e 500 camisas.



